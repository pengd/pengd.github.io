---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- I am an adjunct senior lecturer working with Scientia Professor [Jingling Xue](http://www.cse.unsw.edu.au/~jingling) at School of Computer Science and Engineering, The University of New South Wales. We also open-sourced [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query) that is a scalable datalog-based static program analyser to assist the CodeFuse pre-train.
-->

I am working at [Ant Group](https://www.antgroup.com/) as a Senior Staff Engineer and leading the Intelligent Platform Engineering team. Additionally, I am an Adjunct Associate Professor at the University of New South Wales, Sydney. I also serve as an Industrial PhD Mentor at Zhejiang University.

I earned my PhD degree from UNSW under supervised by Scientia Professor [Jingling Xue](http://www.cse.unsw.edu.au/~jingling). And then I worked as a Research Associate at [Compiler Research Group](http://www.cse.unsw.edu.au/~corg/) and cooperatively developed an inter-procedural dependence analysis tool [SVF](http://svf-tools.github.io/SVF/).

Before joining Ant, I worked at Huawei as a Technical Expert of AI compiler. During the period, I am the founder of MindSpore/AKG ([GitHub](https://github.com/mindspore-ai/akg), [Gitee](https://github.com/mindspore-ai/akg)) which is an open-sourced AI compiler for Huawei Ascend 910.

My team has been dedicated to integrating Large Language Models (LLMs) into real-world industrial scenarios, aiming to enhance the effectiveness and efficiency of software development. The pretrained code LLM, CodeFuse, which was trained by our team at AntGroup, has been open-sourced on [GitHub](https://github.com/codefuse-ai) and [HuggingFace](https://huggingface.co/codefuse-ai). 

We have open-sourced our latest MoE code LLM, Ling-Coder-Lite, available on [GitHub](https://github.com/codefuse-ai/Ling-Coder-Lite) and [HuggingFace](https://huggingface.co/inclusionAI/Ling-Coder-lite). This model is based on the Ant Ling-MoE architecture. Additionally, the [technical report](https://arxiv.org/abs/2503.17793), [SFT dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT) and [DPO dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO) are also openly accessible. 



Research Interests
======
* Large Language Model, AI Software Engineering, AI4SE, SE4AI
* Programming Language, Program Analysis, Software Security
* Parallel Programming and Optimizations for Heterogeneous Systems

News
======
My team is looking for self-motivated technical experts and internship students, who are interested in machine learning, program analysis, AI software engineering. Please no hesitate to contact me (dipeng dot dp at antgroup dot com).

* 2025-09: Our paper, titled "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks" has been accepted by NeurIPS 2025.
* 2025-06: Our paper, titled "Evolving Trends, Patterns, and Hidden Pitfalls: Unveiling JavaScript Feature Usage in the Wild" has been accepted by ICSE 2026.
* 2025-05: We are pleased to announce the updated version of the CGM-72B-V1.2. The model further achieves a remarkable 44.00% resolve rate on the SWE-Bench-Lite leaderboard.[CGM](https://huggingface.co/inclusionAI/Ling-Coder-lite)
* 2025-05: Our paper, titled "GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding" has been accepted to the main conference of ACL 2025.
* 2025-04: Our paper, titled "Tumbling Down the Rabbit Hole: How do Assisting Exploration Strategies Facilitate Grey-box Fuzzing?" wins ACM SIGSOFT Distinguished Paper Award. 
* 2025-03: We have open-sourced our latest MoE code LLM, Ling-Coder-Lite, available on [GitHub](https://github.com/codefuse-ai/Ling-Coder-Lite) and [HuggingFace](https://huggingface.co/inclusionAI/Ling-Coder-lite). This model is based on the Ant Ling-MoE architecture. Additionally, the [technical report](https://arxiv.org/abs/2503.17793), [SFT dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT) and [DPO dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO) are also openly accessible. 
* 2024-12: Our paper, titled "LLM-Powered Static Binary Taint Analysis." has been accepted by [ACM Transactions on Software Engineering and Methodology (TOSEM)](https://dl.acm.org/journal/tosem).
* 2024-11: I was honored to be invited to present Ant Group's recent work on CodeLLM at CCF ChinaSoft 2024. Additionally, our team member, Cong Li, was awarded the Distinguished Dissertation Award by the CCF Systems Software.
* 2024-10: Our paper, titled "Datalog-Based Language-Agnostic Change Impact Analysis for Microservices" has been accepted by ICSE 2025. This paper introduces the application of our datalog-based program analysis system [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query) on the complex change impact analysis of microservices.
* 2024-10: "MiniChecker: Detecting Data Privacy Risk of Abusive Permission Request Behavior in Mini-Programs" earned the distinguished paper award of ASE'24.
* 2024-08: Our paper, titled "Understanding Code Changes Practically with Small-Scale Language Models" has been accepted by ASE 2024. Congratulations to Cong Li, the first author of this work, who joined the Ant Postdoctoral Programme one year ago! Well done! And another paper from our team, titled "MiniChecker: Detecting Data Privacy Risk of Abusive Permission Request Behavior in Mini-Programs", has been accepted by ASE 2024 too.
* 2024-07: Our paper, titled "Tumbling Down the Rabbit Hole: How do Assisting Exploration Strategies Facilitate Grey-box Fuzzing?" has been accepted by ICSE 2025.
* 2024-06: Our paper, titled "Scaling Abstraction Refinement for Program Analyses in Datalog Using Graph Neural Networks"， which introduced an approach to combining graph neural networks and constrait solving to improve program analyses, has been accepted by OOPSLA 2024.
* 2024-05: Our team won 2024 T-Star Award, Ant Group's highest technological award. This award celebrates our innovative contributions to CodeFuse.
* 2024-04: Our paper, titled "Finding and Understanding Defects in Static Analyzers by Constructing Automated Oracles"， which was cooperated with East China Normal University, ETH Zurich, and University of New South Wales, has been accepted by FSE 2024.
* 2024-03: Our paper, titled "Generic Sensitivity: Generics-Guided Context Sensitivity for Pointer Analysis"， which was cooperated with the Chinese Academy of Sciences and Nanjing University, has been accepted by [IEEE Transactions on Software Engineering (TSE)](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32).
* 2023-12: Our two papers "CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model" and "MicroFuzz: An Efficient Fuzzing Framework for Microservices" are accepted by ICSE-SEIP 2024.
* 2023-12: Good News: we opened our datalog-based static program analyser [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query).
* 2023-11: Our paper “Modeling the Interplay between Loop Tiling and Fusion in Optimizing Compilers using Affine Relations” was accepted by [ACM Transactions on Computer Systems (TOCS)](https://dl.acm.org/journal/tocs). We are so fortunate to be the authors of one of the last round of TOCS publications since this journal is no longer accepting submissions and will cease publication after 2023.
* 2023-09: The pretrained code LLM, CodeFuse, which was trained by our team at AntGroup, has been open-sourced on [GitHub](https://github.com/codefuse-ai) and [HuggingFace](https://huggingface.co/codefuse-ai). The technical report has been published on [link](https://arxiv.org/abs/2310.06266). 
* 2023-04: Our paper "Hybrid Inlining: A Framework for Compositional and Context-Sensitive Static Analysis" is accepted by ISSTA 2023.
* 2022-12: Our two papers "Incremental Call Graph Construction in Industrial Practice" and "Scalable Compositional Static Taint Analysis for Sensitive Data Tracing on Industrial Micro-Services" are accepted by ICSE-SEIP 2023.
* 2022-12: Our SAST and SCA products officially enter the Chinese Product and Manufacturer List of Software Supply Chain Security.
* 2022-10: I was invited to serve SANER 2023 as an industrial track PC member.
* 2022-02: I was invited to join the Industry Advisory Board of Monash University.
* 2022-01: Our two papers "Record and Replay of Online Traffic for Microservices with Automatic Mocking Point Identification" and "Field-based Static Taint Analysis for Industrial Microservice" are accepted by ICSE-SEIP 2022.
* 2021-12: I was invited to introduce ANT's AIOps on CCF ChinaSoft 2021. [link](http://chinasoft.ccf.org.cn/schedule/special/6.html)
* 2021-10: I was invited to present our unified program analysis framework on CCF CNCC 2021. [link](https://zhuanlan.zhihu.com/p/417330325)
* 2021-03: Our paper "AKG: Automatic Kernel Generation for Neural Processing Units using Polyhedral Transformations" is accepted by PLDI 2021.
* 2020-10: Our paper "Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data" gains Best Paper Nomination. 
* 2020-07: Our paper "Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data" is accepted by MICRO-53.
* 2020-06: Our AKG is open-sourced. ([GitHub](https://github.com/mindspore-ai/akg), [Gitee](https://github.com/mindspore-ai/akg)). 


