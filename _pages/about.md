---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- I am an adjunct senior lecturer working with Scientia Professor [Jingling Xue](http://www.cse.unsw.edu.au/~jingling) at School of Computer Science and Engineering, The University of New South Wales. We also open-sourced [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query) that is a scalable datalog-based static program analyser to assist the CodeFuse pre-train.
-->

<!-- I am working at [Ant Group](https://www.antgroup.com/) as a Senior Staff Engineer and leading the Intelligent Platform Engineering (IPE) team. Additionally, I am an Adjunct Associate Professor at [the University of New South Wales, Sydney](https://www.unsw.edu.au/staff/peng-di). I also serve as an Industrial PhD Mentor at Zhejiang University.

I earned my PhD degree from UNSW under supervised by IEEE Fellow, Scientia Professor [Jingling Xue](http://www.cse.unsw.edu.au/~jingling). And then I worked as a Research Associate at [Compiler Research Group](http://www.cse.unsw.edu.au/~corg/) and cooperatively developed a program analyser [SVF](http://svf-tools.github.io/SVF/) over LLVM.

Before joining Ant, I worked at Huawei as a Technical Expert of AI compiler. During the period, I am the founder of MindSpore/AKG ([GitHub](https://github.com/mindspore-ai/akg), [Gitee](https://github.com/mindspore-ai/akg)) which is an open-sourced AI compiler for Huawei Ascend 910.

At Ant Group, our IPE team is dedicated to advancing software development and operations by integrating Large Language Models (LLMs) into real-world industrial applications. To support this mission, we are proud to share several major open-source contributions.

<li>CodeFuse: Our foundational pretrained code LLM, designed to enhance coding effectiveness. <a href="https://github.com/codefuse-ai">[GitHub]</a> <a href="https://huggingface.co/codefuse-ai">[HuggingFace]</a> <a href="https://arxiv.org/abs/2310.06266">[Technical report]</a></li>

<li>Ling-Coder-Lite: is Mixture-of-Experts (MoE) code LLM, built on the Ant Ling-MoE architecture. <a href="https://github.com/codefuse-ai/Ling-Coder-Lite">[GitHub]</a> <a href="https://huggingface.co/inclusionAI/Ling-Coder-lite">[HuggingFace]</a> <a href="https://arxiv.org/abs/2503.17793">[Technical report]</a> <a href="https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT">[SFT dataset]</a> <a href="https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO">[DPO dataset]</a></li>

<li>CodeFuse-CGM: is a graph-based framework for software engineering tasks that employs a repository-level code graph to capture structural context. CGM-72B-V1.2 has achieved a leading 44.00% resolve rate on the SWE-Bench-Lite. <a href="https://github.com/codefuse-ai/CodeFuse-CGM">[Github]</a> <a href="https://huggingface.co/inclusionAI/Ling-Coder-lite">[HuggingFace]</a> <a href="https://arxiv.org/abs/2505.16901">[Technical report]</a></li>

<li>OpenDeRisk: Beyond models, we have also open-sourced OpenDeRisk, an AI-native risk intelligence system. It empowers your application to act as a 24/7 risk-aware manager, delivering continuous and comprehensive protection.<a href="https://github.com/derisk-ai/OpenDerisk">[Github]</a> <a href="https://arxiv.org/abs/2510.13561">[Technical report]</a></li> -->




I am a Senior Staff Engineer at <a href="https://www.antgroup.com/" target="_blank">Ant Group</a>, where I lead the <strong>Intelligent Platform Engineering (IPE)</strong> team. My work is dedicated to driving a paradigm shift in the DevOps landscape by deeply integrating Large Language Models (LLMs) and program analysis techniques to enhance developer productivity, software quality, and security.


In parallel with my industry role, I maintain a connection to academia as an Adjunct Associate Professor at <a href="https://www.unsw.edu.au/staff/peng-di" target="_blank">The University of New South Wales</a> and serve as an Industrial PhD Mentor at Zhejiang University.

Experience & Key Projects
=====

<h3>Ant Group (2020 &ndash; Present)</h3>

My primary focus is on building enterprise-scale products that redefine software engineering for Ant Group's internal infrastructure. While we are proud of our open-source contributions, they represent just the tip of the iceberg of our team's overall innovation and impact.


<ul>
    <li><strong>CodeFuse LLM:</strong> : Our foundational pretrained code LLM, designed to enhance coding effectiveness. It has been successfully implemented in critical software lifecycle across the group, covering AI coding and operations, code quality, security and relibility assurance.
    <br>
        <em>[<a href="https://github.com/codefuse-ai" target="_blank">CodeFuse</a>] [<a href="https://github.com/codefuse-ai/CodeFuse-CGM">CodeFuse-CGM</a>] [<a href="https://huggingface.co/inclusionAI/Ling-Coder-lite">Ling-Coder-lite</a>] </em>
        <br>
        <em>contribute to [<a href="https://www.weavefox.cn/" target="_blank">WeaveFox</a>] [<a href="https://www.tbox.cn/" target="_blank">TBox</a>]</em>
        </li>
    <li>
        <strong>OpenDeRisk:</strong> an AI-native risk intelligence system. It empowers your application to act as a 24/7 risk-aware manager, delivering continuous and comprehensive protection.
        <br>
        <em>[<a href="https://github.com/derisk-ai/OpenDerisk" target="_blank">OpenDeRisk on GitHub</a>]</em>
    </li>
    <li>
        <strong>OpAgent:</strong> our new web agent that achieves a state-of-the-art 71.6% success rate on the WebArena benchmark! Most web agents fail because they are trained on static data. OpAgent is different. It learns by interacting directly with live websites using Agentic RL (Reinforcement Learning), allowing it to adapt to the web's dynamic nature. Its modular framework (Planner, Grounder, Reflector) enables robust self-correction, mastering complex web tasks where others struggle.
        <br>
        <em>[<a href="https://github.com/codefuse-ai/OpAgent">OpAgent on Github</a>] [<a href="https://huggingface.co/codefuse-ai/OpAgent-32B">OpAgent on HuggingFace</a>] [<a href="https://github.com/codefuse-ai/OpAgent/blob/main/technical_report/OpAgent.pdf">Technical report</a>]</em>
    </li>
</ul>
<h3>Huawei (2018 &ndash; 2020)</h3>
<p>
    Before joining Ant, I worked at Huawei as a Technical Expert of AI compiler to build AI infra for Huawei AI ecosystem. 
</p>
<ul>
    <li>
      <strong>MindSpore/AKG:</strong> I co-designed the MindSpore framework and founded its AKG compiler for the Ascend chip, driving its commercialization through performance optimization. I also played a key role in open-sourcing the platform, establishing its developer ecosystem.
      <br>
      <em>[<a href="https://www.mindspore.cn/en/" target="_blank">MindSpore</a>][<a href="https://github.com/mindspore-ai/akg" target="_blank">MindSpore/AKG on GitHub</a>]</em>
    </li>
</ul>

<h3>The University of New South Wales (2013 &ndash; 2018)</h3>
<p>
    During my time in academia as a Lecturer and Associate Professor, my research had a strong focus on real-world application and commercial translation.
</p>
<ul>
    <li>
        <strong>SVF (Static Value-Flow Analysis):</strong> I cooperatively developed a program analyser SVF, a leading pointer analysis framework built on LLVM. Its core technology became a cornerstone for multiple commercial software security products, effectively shaping the ecosystem in this domain.
        <br>
        <em>[<a href="http://svf-tools.github.io/SVF/" target="_blank">SVF Project Page</a>]</em>
    </li>
</ul>



Research Interests
======
* Code Large Language Model, AI Software Engineering
* Programming Language, Program Analysis, Software Security
* AI Infra, Parallel Programming

News
======
My team is looking for self-motivated technical experts and internship students, who are interested in machine learning, program analysis, AI software engineering. Please no hesitate to contact me (dipeng dot dp at antgroup dot com).

* 2026-02： We're excited to open-source OpAgent, our new web agent that achieves a state-of-the-art 71.6% success rate on the WebArena benchmark! Please check repository [<a href="https://github.com/codefuse-ai/OpAgent">OpAgent on Github</a>] [<a href="https://huggingface.co/codefuse-ai/OpAgent-32B">OpAgent on HuggingFace</a>] [<a href="https://github.com/codefuse-ai/OpAgent/blob/main/technical_report/OpAgent.pdf">Technical report</a>].
* 2026-01: “Prompting Frameworks for Large Language Models: A Survey” has been accepted by ACM Computing Surveys. 
* 2025-12: Our two papers, introducing our open-sourced OpenDerisk and Codefuse-Query respectively, has been accepted by ICSE-SEIP 2026. 
* 2025-11: Our binary analysis work, titled "BIT: Empowering Binary Analysis Through the LLVM Toolchain" has been accepted by CGO 2026. This paper describes the application of binary analysis technology in Ant Group's real-world IoT scenarios (Alipay Tap to Pay), identifying program issues through the collaborative analysis of data flows using both source code and binary. 
* 2025-09: Our paper, titled "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks" has been accepted by NeurIPS 2025.
* 2025-08: We are proud to open-source OpenDeRisk, an AI-native risk intelligence system that transforms your application into a 24/7 risk-aware manager, offering continuous, comprehensive, and deep-layer protection. Available now on [GitHub](https://github.com/derisk-ai/OpenDerisk).
* 2025-06: Our paper, titled "Evolving Trends, Patterns, and Hidden Pitfalls: Unveiling JavaScript Feature Usage in the Wild" has been accepted by ICSE 2026.
* 2025-05: We are pleased to announce the updated version of the CGM-72B-V1.2. The model further achieves a remarkable 44.00% resolve rate on the SWE-Bench-Lite leaderboard.[CGM](https://huggingface.co/inclusionAI/Ling-Coder-lite)
* 2025-05: Our paper, titled "GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding" has been accepted to the main conference of ACL 2025.
* 2025-04: Our paper, titled "Tumbling Down the Rabbit Hole: How do Assisting Exploration Strategies Facilitate Grey-box Fuzzing?" wins ACM SIGSOFT Distinguished Paper Award. 
* 2025-03: We have open-sourced our latest MoE code LLM, Ling-Coder-Lite, available on [GitHub](https://github.com/codefuse-ai/Ling-Coder-Lite) and [HuggingFace](https://huggingface.co/inclusionAI/Ling-Coder-lite). This model is based on the Ant Ling-MoE architecture. Additionally, the [technical report](https://arxiv.org/abs/2503.17793), [SFT dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-SFT) and [DPO dataset](https://huggingface.co/datasets/inclusionAI/Ling-Coder-DPO) are also openly accessible. 
* 2024-12: Our paper, titled "LLM-Powered Static Binary Taint Analysis." has been accepted by [ACM Transactions on Software Engineering and Methodology (TOSEM)](https://dl.acm.org/journal/tosem).
* 2024-11: I was honored to be invited to present Ant Group's recent work on CodeLLM at CCF ChinaSoft 2024. Additionally, our team member, Cong Li, was awarded the Distinguished Dissertation Award by the CCF Systems Software.
* 2024-10: Our paper, titled "Datalog-Based Language-Agnostic Change Impact Analysis for Microservices" has been accepted by ICSE 2025. This paper introduces the application of our datalog-based program analysis system [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query) on the complex change impact analysis of microservices.
* 2024-10: "MiniChecker: Detecting Data Privacy Risk of Abusive Permission Request Behavior in Mini-Programs" earned the distinguished paper award of ASE'24.
* 2024-08: Our paper, titled "Understanding Code Changes Practically with Small-Scale Language Models" has been accepted by ASE 2024. Congratulations to Cong Li, the first author of this work, who joined the Ant Postdoctoral Programme one year ago! Well done! And another paper from our team, titled "MiniChecker: Detecting Data Privacy Risk of Abusive Permission Request Behavior in Mini-Programs", has been accepted by ASE 2024 too.
* 2024-07: Our paper, titled "Tumbling Down the Rabbit Hole: How do Assisting Exploration Strategies Facilitate Grey-box Fuzzing?" has been accepted by ICSE 2025.
* 2024-06: Our paper, titled "Scaling Abstraction Refinement for Program Analyses in Datalog Using Graph Neural Networks"， which introduced an approach to combining graph neural networks and constrait solving to improve program analyses, has been accepted by OOPSLA 2024.
* 2024-05: Our team won 2024 T-Star Award, Ant Group's highest technological award. This award celebrates our innovative contributions to CodeFuse.
* 2024-04: Our paper, titled "Finding and Understanding Defects in Static Analyzers by Constructing Automated Oracles"， which was cooperated with East China Normal University, ETH Zurich, and University of New South Wales, has been accepted by FSE 2024.
* 2024-03: Our paper, titled "Generic Sensitivity: Generics-Guided Context Sensitivity for Pointer Analysis"， which was cooperated with the Chinese Academy of Sciences and Nanjing University, has been accepted by [IEEE Transactions on Software Engineering (TSE)](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32).
* 2023-12: Our two papers "CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model" and "MicroFuzz: An Efficient Fuzzing Framework for Microservices" are accepted by ICSE-SEIP 2024.
* 2023-12: Good News: we opened our datalog-based static program analyser [CodeFuse-Query](https://github.com/codefuse-ai/CodeFuse-Query).
* 2023-11: Our paper “Modeling the Interplay between Loop Tiling and Fusion in Optimizing Compilers using Affine Relations” was accepted by [ACM Transactions on Computer Systems (TOCS)](https://dl.acm.org/journal/tocs). We are so fortunate to be the authors of one of the last round of TOCS publications since this journal is no longer accepting submissions and will cease publication after 2023.
* 2023-09: The pretrained code LLM, CodeFuse, which was trained by our team at AntGroup, has been open-sourced on [GitHub](https://github.com/codefuse-ai) and [HuggingFace](https://huggingface.co/codefuse-ai). The technical report has been published on [link](https://arxiv.org/abs/2310.06266). 
* 2023-04: Our paper "Hybrid Inlining: A Framework for Compositional and Context-Sensitive Static Analysis" is accepted by ISSTA 2023.
* 2022-12: Our two papers "Incremental Call Graph Construction in Industrial Practice" and "Scalable Compositional Static Taint Analysis for Sensitive Data Tracing on Industrial Micro-Services" are accepted by ICSE-SEIP 2023.
* 2022-12: Our SAST and SCA products officially enter the Chinese Product and Manufacturer List of Software Supply Chain Security.
* 2022-10: I was invited to serve SANER 2023 as an industrial track PC member.
* 2022-02: I was invited to join the Industry Advisory Board of Monash University.
* 2022-01: Our two papers "Record and Replay of Online Traffic for Microservices with Automatic Mocking Point Identification" and "Field-based Static Taint Analysis for Industrial Microservice" are accepted by ICSE-SEIP 2022.
* 2021-12: I was invited to introduce ANT's AIOps on CCF ChinaSoft 2021. [link](http://chinasoft.ccf.org.cn/schedule/special/6.html)
* 2021-10: I was invited to present our unified program analysis framework on CCF CNCC 2021. [link](https://zhuanlan.zhihu.com/p/417330325)
* 2021-03: Our paper "AKG: Automatic Kernel Generation for Neural Processing Units using Polyhedral Transformations" is accepted by PLDI 2021.
* 2020-10: Our paper "Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data" gains Best Paper Nomination. 
* 2020-07: Our paper "Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data" is accepted by MICRO-53.
* 2020-06: Our AKG is open-sourced. ([GitHub](https://github.com/mindspore-ai/akg), [Gitee](https://github.com/mindspore-ai/akg)). 


